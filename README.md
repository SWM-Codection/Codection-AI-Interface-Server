# Codection-Github-AI-Interface-Server


# 선택 근거

---
1. api 서버를 두는 이유
- 추후 openai api가 아닌 ai 서버로 교체할 때 다른 부분에 영향이 가지 않도록 이에 대한 인터페이스를 담당하는 서버를 두는 것 
2. FastAPI로 서버를 구축한 이유
- python은 OpenAI에서 api를 유지보수하고 있어서 추후 라이브러리가 업데이트 돼도 금방해결 가능



## PR 리뷰 기능

---
- [x] 파일의 내용을 OpenAI API로 넘겨서 결과를 받아오기
- [x] 각 파일마다 Thread(OpenAI API)를 생성하여 별개의 컨텍스트 윈도우 생성 ->  프롬프트 엔지니어링에 대해선 좀 더 연구가 필요할듯 싶어 일단 파일 별로 리뷰
- [ ] 각 스레드의 리뷰 결과를 받아서 파싱하여 데이터 베이스 PR comment로 저장
- [ ] gitea와 서버와 연동할 메세지 큐를 일단 설정해보기 

## 생각해볼만한 부분

각 부분에 대해서 본인의 생각을 말씀해주세요. 여기에 제안되지 않은 방식이라도 좀 더 좋은 방식이 생각 나시면
제시해주세요.

---
1. 풀 리퀘스트에 새로운 PR이 날아오면 어떻게 처리해야하는가?
    - 맨 처음에 생성될 때는 자동으로 달아주고 리뷰어나 리뷰이가 직접 리뷰 생성 버튼을 눌러서 리뷰를 새롭게 만드는 방식 <- 현재는 이 방식을 채택 
    - 매번 커밋이 생길 때마다 감지해서 코드 리뷰를 처리하는 방식


2. OpenAI의 서버 문제로 요청이 완료되지 않고 Time Out이 발생하면 어떻게 처리하는가?
    - 이진수 백오프 방식()
    - 사용자가 나중에 알아서 요청하게 만든다. <- 현재는 이 방식을 생각 중


3. API 서버에서 데이터 베이스에 PR Comment를 저장하는 방식에 대해

   - 일단 이 API 서버에서 PR 커멘트를 데이터베이스에 직접 넣는 방식을 생각해봤는데 외부 API에서 DB를 접근해서 저장하는 게 맞는지 모르겟음..
   - 그렇다고해서 Go 서버에게 직접 데이터 베이스에 저장하는 방식도 좋은 방식인지는 잘 모르겠음.